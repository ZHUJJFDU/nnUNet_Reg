#!/usr/bin/env python3
"""
æµ‹è¯•è„šæœ¬ï¼šéªŒè¯DualDecoderUNetè®­ç»ƒå™¨æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import torch
import numpy as np
from torch import nn

def test_dual_decoder_trainer():
    """
    æµ‹è¯•DualDecoderUNetè®­ç»ƒå™¨çš„åŸºæœ¬åŠŸèƒ½
    """
    print("å¼€å§‹æµ‹è¯•DualDecoderUNetè®­ç»ƒå™¨...")
    
    try:
        # å¯¼å…¥è®­ç»ƒå™¨
        from nnunetv2.training.nnUNetTrainer.variants.network_architecture.nnUNetTrainerDualDecoder import nnUNetTrainerDualDecoder
        print("âœ… æˆåŠŸå¯¼å…¥nnUNetTrainerDualDecoder")
        
        # æµ‹è¯•ç½‘ç»œæ„å»º
        arch_init_kwargs = {
            'conv_op': torch.nn.Conv3d,
            'norm_op': torch.nn.BatchNorm3d,
            'norm_op_kwargs': {'eps': 1e-5, 'affine': True},
            'dropout_op': None,
            'dropout_op_kwargs': None,
            'nonlin': torch.nn.ReLU,
            'nonlin_kwargs': {'inplace': True},
            'n_stages': 5,
            'features_per_stage': [32, 64, 128, 256, 512],
            'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]],
            'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]],
            'n_conv_per_stage': [2, 2, 2, 2, 2],
            'n_conv_per_stage_decoder': [2, 2, 2, 2],
            'conv_bias': False,
            'deep_supervision': False
        }
        
        network = nnUNetTrainerDualDecoder.build_network_architecture(
            architecture_class_name='dynamic_network_architectures.architectures.unet.DualDecoderUNet',
            arch_init_kwargs=arch_init_kwargs,
            arch_init_kwargs_req_import=[],
            num_input_channels=4,
            num_output_channels=2,
            enable_deep_supervision=False
        )
        print("âœ… æˆåŠŸæ„å»ºDualDecoderUNetç½‘ç»œ")
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        network = network.to(device)
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        batch_size = 1
        input_channels = 4
        patch_size = [64, 64, 64]
        
        test_input = torch.randn(batch_size, input_channels, *patch_size).to(device)
        
        with torch.no_grad():
            output = network(test_input)
            
        if isinstance(output, (tuple, list)):
            seg_output, reg_output = output
            print(f"âœ… å‰å‘ä¼ æ’­æˆåŠŸ")
            print(f"   åˆ†å‰²è¾“å‡ºå½¢çŠ¶: {seg_output.shape}")
            print(f"   å›å½’è¾“å‡ºå½¢çŠ¶: {reg_output.shape}")
        elif isinstance(output, dict):
            seg_output = output['segmentation']
            reg_output = output.get('regression', None)
            print(f"âœ… å‰å‘ä¼ æ’­æˆåŠŸ")
            print(f"   åˆ†å‰²è¾“å‡ºå½¢çŠ¶: {seg_output.shape}")
            if reg_output is not None:
                print(f"   å›å½’è¾“å‡ºå½¢çŠ¶: {reg_output.shape}")
        else:
            print(f"âœ… å‰å‘ä¼ æ’­æˆåŠŸï¼Œè¾“å‡ºå½¢çŠ¶: {output.shape}")
        
        # æµ‹è¯•æŸå¤±è®¡ç®—
        print("\næµ‹è¯•æŸå¤±è®¡ç®—...")
        
        # åˆ›å»ºæ¨¡æ‹Ÿçš„è®­ç»ƒæ‰¹æ¬¡
        batch = {
            'data': test_input,
            'target': torch.randint(0, 2, (batch_size, *patch_size)).to(device),
            'regression_target': torch.randn(batch_size, 1).to(device)
        }
        
        # åˆ›å»ºæ¨¡æ‹Ÿçš„è®­ç»ƒå™¨å®ä¾‹ï¼ˆä»…ç”¨äºæµ‹è¯•æŸå¤±è®¡ç®—é€»è¾‘ï¼‰
        class MockTrainer:
            def __init__(self):
                self.device = device
                self.network = network
                self.loss = nn.CrossEntropyLoss()
                self.optimizer = torch.optim.SGD(network.parameters(), lr=0.01)
                self.grad_scaler = None
        
        mock_trainer = MockTrainer()
        
        # æ¨¡æ‹Ÿè®­ç»ƒæ­¥éª¤çš„æŸå¤±è®¡ç®—éƒ¨åˆ†
        data = batch['data']
        target = batch['target']
        
        with torch.no_grad():
            output = network(data)
            
            if isinstance(output, (tuple, list)) and len(output) == 2:
                seg_output, reg_output = output
            elif isinstance(output, dict):
                seg_output = output['segmentation']
                reg_output = output.get('regression', None)
            else:
                seg_output = output
                reg_output = None
            
            # è®¡ç®—åˆ†å‰²æŸå¤±ï¼ˆç®€åŒ–ç‰ˆï¼‰
            if seg_output.shape[1] > 1:  # å¤šç±»åˆ†å‰²
                seg_loss = nn.CrossEntropyLoss()(seg_output, target.long())
            else:  # äºŒåˆ†ç±»
                seg_loss = nn.BCEWithLogitsLoss()(seg_output, target.float().unsqueeze(1))
            
            total_loss = seg_loss
            
            # å¦‚æœæœ‰å›å½’è¾“å‡ºï¼Œè®¡ç®—å›å½’æŸå¤±
            if reg_output is not None and 'regression_target' in batch:
                reg_target = batch['regression_target']
                reg_loss = nn.MSELoss()(reg_output, reg_target)
                reg_weight = getattr(network, 'regression_loss_weight', 0.1)
                total_loss = seg_loss + reg_weight * reg_loss
                print(f"   åˆ†å‰²æŸå¤±: {seg_loss.item():.4f}")
                print(f"   å›å½’æŸå¤±: {reg_loss.item():.4f}")
                print(f"   å›å½’æƒé‡: {reg_weight}")
                print(f"   æ€»æŸå¤±: {total_loss.item():.4f}")
            else:
                print(f"   åˆ†å‰²æŸå¤±: {seg_loss.item():.4f}")
                print(f"   æ€»æŸå¤±: {total_loss.item():.4f}")
        
        print("âœ… æŸå¤±è®¡ç®—æµ‹è¯•æˆåŠŸ")
        
        # æµ‹è¯•ä¸åŒepochæ•°çš„è®­ç»ƒå™¨
        print("\næµ‹è¯•ä¸åŒepochæ•°çš„è®­ç»ƒå™¨...")
        
        from nnunetv2.training.nnUNetTrainer.variants.network_architecture.nnUNetTrainerDualDecoder import (
            nnUNetTrainerDualDecoder_5epochs,
            nnUNetTrainerDualDecoder_10epochs,
            nnUNetTrainerDualDecoder_50epochs
        )
        
        epoch_trainers = {
            '5epochs': nnUNetTrainerDualDecoder_5epochs,
            '10epochs': nnUNetTrainerDualDecoder_10epochs,
            '50epochs': nnUNetTrainerDualDecoder_50epochs
        }
        
        for name, trainer_class in epoch_trainers.items():
            print(f"âœ… æˆåŠŸå¯¼å…¥ {name} è®­ç»ƒå™¨")
        
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼DualDecoderUNetè®­ç»ƒå™¨å¯ä»¥æ­£å¸¸ä½¿ç”¨ã€‚")
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_network_only():
    """
    ä»…æµ‹è¯•ç½‘ç»œæœ¬èº«ï¼Œä¸ä¾èµ–è®­ç»ƒå™¨
    """
    print("\nå¼€å§‹æµ‹è¯•DualDecoderUNetç½‘ç»œæœ¬èº«...")
    
    try:
        # ç›´æ¥å¯¼å…¥ç½‘ç»œ
        from dynamic_network_architectures.architectures.unet import DualDecoderUNet
        print("âœ… æˆåŠŸå¯¼å…¥DualDecoderUNet")
        
        # åˆ›å»ºç½‘ç»œå®ä¾‹
        network = DualDecoderUNet(
            input_channels=4,
            n_stages=5,
            features_per_stage=[32, 64, 128, 256, 512],
            conv_op=torch.nn.Conv3d,
            kernel_sizes=3,
            strides=[1, 2, 2, 2, 2],
            n_conv_per_stage=2,
            num_classes=2,
            num_regression_outputs=1,
            n_conv_per_stage_decoder=2,
            deep_supervision=False,
        )
        print("âœ… æˆåŠŸåˆ›å»ºDualDecoderUNetå®ä¾‹")
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        network = network.to(device)
        
        test_input = torch.randn(1, 4, 64, 64, 64).to(device)
        
        with torch.no_grad():
            output = network(test_input)
            
        if isinstance(output, (tuple, list)):
            seg_output, reg_output = output
            print(f"âœ… ç½‘ç»œå‰å‘ä¼ æ’­æˆåŠŸ")
            print(f"   åˆ†å‰²è¾“å‡ºå½¢çŠ¶: {seg_output.shape}")
            print(f"   å›å½’è¾“å‡ºå½¢çŠ¶: {reg_output.shape}")
            print(f"   å›å½’æŸå¤±æƒé‡: {network.regression_loss_weight}")
        
        return True
        
    except Exception as e:
        print(f"âŒ ç½‘ç»œæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == '__main__':
    print("DualDecoderUNet è®­ç»ƒå™¨æµ‹è¯•")
    print("=" * 50)
    
    # é¦–å…ˆæµ‹è¯•ç½‘ç»œæœ¬èº«
    network_ok = test_network_only()
    
    if network_ok:
        # ç„¶åæµ‹è¯•è®­ç»ƒå™¨
        trainer_ok = test_dual_decoder_trainer()
        
        if trainer_ok:
            print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ‚¨å¯ä»¥å¼€å§‹ä½¿ç”¨DualDecoderUNetè¿›è¡Œè®­ç»ƒäº†ã€‚")
            print("\nä¸‹ä¸€æ­¥:")
            print("1. å‡†å¤‡æ‚¨çš„æ•°æ®é›†")
            print("2. è¿è¡Œæ•°æ®é¢„å¤„ç†")
            print("3. ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¼€å§‹è®­ç»ƒ:")
            print("   python examples/train_dual_decoder_example.py --dataset YourDataset")
        else:
            print("\nâŒ è®­ç»ƒå™¨æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
    else:
        print("\nâŒ ç½‘ç»œæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")